{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import emoji\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Dropout, SimpleRNN,LSTM, Activation\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{':1st_place_medal:': '🥇',\n",
       " ':2nd_place_medal:': '🥈',\n",
       " ':3rd_place_medal:': '🥉',\n",
       " ':AB_button_(blood_type):': '🆎',\n",
       " ':ATM_sign:': '🏧',\n",
       " ':A_button_(blood_type):': '🅰',\n",
       " ':A_button_(blood_type)_selector:': '🅰️',\n",
       " ':Afghanistan:': '🇦🇫',\n",
       " ':Aland_Islands:': '🇦🇽',\n",
       " ':Albania:': '🇦🇱',\n",
       " ':Algeria:': '🇩🇿',\n",
       " ':American_Samoa:': '🇦🇸',\n",
       " ':Andorra:': '🇦🇩',\n",
       " ':Angola:': '🇦🇴',\n",
       " ':Anguilla:': '🇦🇮',\n",
       " ':Antarctica:': '🇦🇶',\n",
       " ':Antigua_&_Barbuda:': '🇦🇬',\n",
       " ':Aquarius:': '♒',\n",
       " ':Argentina:': '🇦🇷',\n",
       " ':Aries:': '♈',\n",
       " ':Armenia:': '🇦🇲',\n",
       " ':Aruba:': '🇦🇼',\n",
       " ':Ascension_Island:': '🇦🇨',\n",
       " ':Australia:': '🇦🇺',\n",
       " ':Austria:': '🇦🇹',\n",
       " ':Azerbaijan:': '🇦🇿',\n",
       " ':BACK_arrow:': '🔙',\n",
       " ':B_button_(blood_type):': '🅱',\n",
       " ':B_button_(blood_type)_selector:': '🅱️',\n",
       " ':Bahamas:': '🇧🇸',\n",
       " ':Bahrain:': '🇧🇭',\n",
       " ':Bangladesh:': '🇧🇩',\n",
       " ':Barbados:': '🇧🇧',\n",
       " ':Belarus:': '🇧🇾',\n",
       " ':Belgium:': '🇧🇪',\n",
       " ':Belize:': '🇧🇿',\n",
       " ':Benin:': '🇧🇯',\n",
       " ':Bermuda:': '🇧🇲',\n",
       " ':Bhutan:': '🇧🇹',\n",
       " ':Bolivia:': '🇧🇴',\n",
       " ':Bosnia_&_Herzegovina:': '🇧🇦',\n",
       " ':Botswana:': '🇧🇼',\n",
       " ':Bouvet_Island:': '🇧🇻',\n",
       " ':Brazil:': '🇧🇷',\n",
       " ':British_Indian_Ocean_Territory:': '🇮🇴',\n",
       " ':British_Virgin_Islands:': '🇻🇬',\n",
       " ':Brunei:': '🇧🇳',\n",
       " ':Bulgaria:': '🇧🇬',\n",
       " ':Burkina_Faso:': '🇧🇫',\n",
       " ':Burundi:': '🇧🇮',\n",
       " ':CL_button:': '🆑',\n",
       " ':COOL_button:': '🆒',\n",
       " ':Cambodia:': '🇰🇭',\n",
       " ':Cameroon:': '🇨🇲',\n",
       " ':Canada:': '🇨🇦',\n",
       " ':Canary_Islands:': '🇮🇨',\n",
       " ':Cancer:': '♋',\n",
       " ':Cape_Verde:': '🇨🇻',\n",
       " ':Capricorn:': '♑',\n",
       " ':Caribbean_Netherlands:': '🇧🇶',\n",
       " ':Cayman_Islands:': '🇰🇾',\n",
       " ':Central_African_Republic:': '🇨🇫',\n",
       " ':Ceuta_&_Melilla:': '🇪🇦',\n",
       " ':Chad:': '🇹🇩',\n",
       " ':Chile:': '🇨🇱',\n",
       " ':China:': '🇨🇳',\n",
       " ':Christmas_Island:': '🇨🇽',\n",
       " ':Christmas_tree:': '🎄',\n",
       " ':Clipperton_Island:': '🇨🇵',\n",
       " ':Cocos_(Keeling)_Islands:': '🇨🇨',\n",
       " ':Colombia:': '🇨🇴',\n",
       " ':Comoros:': '🇰🇲',\n",
       " ':Congo_-_Brazzaville:': '🇨🇬',\n",
       " ':Congo_-_Kinshasa:': '🇨🇩',\n",
       " ':Cook_Islands:': '🇨🇰',\n",
       " ':Costa_Rica:': '🇨🇷',\n",
       " ':Croatia:': '🇭🇷',\n",
       " ':Cuba:': '🇨🇺',\n",
       " ':Curaçao:': '🇨🇼',\n",
       " ':Cyprus:': '🇨🇾',\n",
       " ':Czechia:': '🇨🇿',\n",
       " ':Côte_d’Ivoire:': '🇨🇮',\n",
       " ':Denmark:': '🇩🇰',\n",
       " ':Diego_Garcia:': '🇩🇬',\n",
       " ':Djibouti:': '🇩🇯',\n",
       " ':Dominica:': '🇩🇲',\n",
       " ':Dominican_Republic:': '🇩🇴',\n",
       " ':END_arrow:': '🔚',\n",
       " ':Ecuador:': '🇪🇨',\n",
       " ':Egypt:': '🇪🇬',\n",
       " ':El_Salvador:': '🇸🇻',\n",
       " ':England:': '🏴\\U000e0067\\U000e0062\\U000e0065\\U000e006e\\U000e0067\\U000e007f',\n",
       " ':Equatorial_Guinea:': '🇬🇶',\n",
       " ':Eritrea:': '🇪🇷',\n",
       " ':Estonia:': '🇪🇪',\n",
       " ':Ethiopia:': '🇪🇹',\n",
       " ':European_Union:': '🇪🇺',\n",
       " ':FREE_button:': '🆓',\n",
       " ':Falkland_Islands:': '🇫🇰',\n",
       " ':Faroe_Islands:': '🇫🇴',\n",
       " ':Fiji:': '🇫🇯',\n",
       " ':Finland:': '🇫🇮',\n",
       " ':France:': '🇫🇷',\n",
       " ':French_Guiana:': '🇬🇫',\n",
       " ':French_Polynesia:': '🇵🇫',\n",
       " ':French_Southern_Territories:': '🇹🇫',\n",
       " ':Gabon:': '🇬🇦',\n",
       " ':Gambia:': '🇬🇲',\n",
       " ':Gemini:': '♊',\n",
       " ':Georgia:': '🇬🇪',\n",
       " ':Germany:': '🇩🇪',\n",
       " ':Ghana:': '🇬🇭',\n",
       " ':Gibraltar:': '🇬🇮',\n",
       " ':Greece:': '🇬🇷',\n",
       " ':Greenland:': '🇬🇱',\n",
       " ':Grenada:': '🇬🇩',\n",
       " ':Guadeloupe:': '🇬🇵',\n",
       " ':Guam:': '🇬🇺',\n",
       " ':Guatemala:': '🇬🇹',\n",
       " ':Guernsey:': '🇬🇬',\n",
       " ':Guinea-Bissau:': '🇬🇼',\n",
       " ':Guinea:': '🇬🇳',\n",
       " ':Guyana:': '🇬🇾',\n",
       " ':Haiti:': '🇭🇹',\n",
       " ':Heard_&_McDonald_Islands:': '🇭🇲',\n",
       " ':Honduras:': '🇭🇳',\n",
       " ':Hong_Kong_SAR_China:': '🇭🇰',\n",
       " ':Hungary:': '🇭🇺',\n",
       " ':ID_button:': '🆔',\n",
       " ':Iceland:': '🇮🇸',\n",
       " ':India:': '🇮🇳',\n",
       " ':Indonesia:': '🇮🇩',\n",
       " ':Iran:': '🇮🇷',\n",
       " ':Iraq:': '🇮🇶',\n",
       " ':Ireland:': '🇮🇪',\n",
       " ':Isle_of_Man:': '🇮🇲',\n",
       " ':Israel:': '🇮🇱',\n",
       " ':Italy:': '🇮🇹',\n",
       " ':Jamaica:': '🇯🇲',\n",
       " ':Japan:': '🇯🇵',\n",
       " ':Japanese_acceptable_button:': '🉑',\n",
       " ':Japanese_application_button:': '🈸',\n",
       " ':Japanese_bargain_button:': '🉐',\n",
       " ':Japanese_castle:': '🏯',\n",
       " ':Japanese_congratulations_button:': '㊗',\n",
       " ':Japanese_discount_button:': '🈹',\n",
       " ':Japanese_dolls:': '🎎',\n",
       " ':Japanese_free_of_charge_button:': '🈚',\n",
       " ':Japanese_here_button:': '🈁',\n",
       " ':Japanese_monthly_amount_button:': '🈷',\n",
       " ':Japanese_no_vacancy_button:': '🈵',\n",
       " ':Japanese_not_free_of_charge_button:': '🈶',\n",
       " ':Japanese_open_for_business_button:': '🈺',\n",
       " ':Japanese_passing_grade_button:': '🈴',\n",
       " ':Japanese_post_office:': '🏣',\n",
       " ':Japanese_prohibited_button:': '🈲',\n",
       " ':Japanese_reserved_button:': '🈯',\n",
       " ':Japanese_secret_button:': '㊙',\n",
       " ':Japanese_service_charge_button:': '🈂',\n",
       " ':Japanese_symbol_for_beginner:': '🔰',\n",
       " ':Japanese_vacancy_button:': '🈳',\n",
       " ':Japanese_congratulations_button_selector:': '㊗️',\n",
       " ':Japanese_monthly_amount_button_selector:': '🈷️',\n",
       " ':Japanese_secret_button_selector:': '㊙️',\n",
       " ':Japanese_service_charge_button_selector:': '🈂️',\n",
       " ':Jersey:': '🇯🇪',\n",
       " ':Jordan:': '🇯🇴',\n",
       " ':Kazakhstan:': '🇰🇿',\n",
       " ':Kenya:': '🇰🇪',\n",
       " ':Kiribati:': '🇰🇮',\n",
       " ':Kosovo:': '🇽🇰',\n",
       " ':Kuwait:': '🇰🇼',\n",
       " ':Kyrgyzstan:': '🇰🇬',\n",
       " ':Laos:': '🇱🇦',\n",
       " ':Latvia:': '🇱🇻',\n",
       " ':Lebanon:': '🇱🇧',\n",
       " ':Leo:': '♌',\n",
       " ':Lesotho:': '🇱🇸',\n",
       " ':Liberia:': '🇱🇷',\n",
       " ':Libra:': '♎',\n",
       " ':Libya:': '🇱🇾',\n",
       " ':Liechtenstein:': '🇱🇮',\n",
       " ':Lithuania:': '🇱🇹',\n",
       " ':Luxembourg:': '🇱🇺',\n",
       " ':Macau_SAR_China:': '🇲🇴',\n",
       " ':Macedonia:': '🇲🇰',\n",
       " ':Madagascar:': '🇲🇬',\n",
       " ':Malawi:': '🇲🇼',\n",
       " ':Malaysia:': '🇲🇾',\n",
       " ':Maldives:': '🇲🇻',\n",
       " ':Mali:': '🇲🇱',\n",
       " ':Malta:': '🇲🇹',\n",
       " ':Marshall_Islands:': '🇲🇭',\n",
       " ':Martinique:': '🇲🇶',\n",
       " ':Mauritania:': '🇲🇷',\n",
       " ':Mauritius:': '🇲🇺',\n",
       " ':Mayotte:': '🇾🇹',\n",
       " ':Mexico:': '🇲🇽',\n",
       " ':Micronesia:': '🇫🇲',\n",
       " ':Moldova:': '🇲🇩',\n",
       " ':Monaco:': '🇲🇨',\n",
       " ':Mongolia:': '🇲🇳',\n",
       " ':Montenegro:': '🇲🇪',\n",
       " ':Montserrat:': '🇲🇸',\n",
       " ':Morocco:': '🇲🇦',\n",
       " ':Mozambique:': '🇲🇿',\n",
       " ':Mrs._Claus:': '🤶',\n",
       " ':Mrs._Claus_dark_skin_tone:': '🤶🏿',\n",
       " ':Mrs._Claus_light_skin_tone:': '🤶🏻',\n",
       " ':Mrs._Claus_medium-dark_skin_tone:': '🤶🏾',\n",
       " ':Mrs._Claus_medium-light_skin_tone:': '🤶🏼',\n",
       " ':Mrs._Claus_medium_skin_tone:': '🤶🏽',\n",
       " ':Myanmar_(Burma):': '🇲🇲',\n",
       " ':NEW_button:': '🆕',\n",
       " ':NG_button:': '🆖',\n",
       " ':Namibia:': '🇳🇦',\n",
       " ':Nauru:': '🇳🇷',\n",
       " ':Nepal:': '🇳🇵',\n",
       " ':Netherlands:': '🇳🇱',\n",
       " ':New_Caledonia:': '🇳🇨',\n",
       " ':New_Zealand:': '🇳🇿',\n",
       " ':Nicaragua:': '🇳🇮',\n",
       " ':Niger:': '🇳🇪',\n",
       " ':Nigeria:': '🇳🇬',\n",
       " ':Niue:': '🇳🇺',\n",
       " ':Norfolk_Island:': '🇳🇫',\n",
       " ':North_Korea:': '🇰🇵',\n",
       " ':Northern_Mariana_Islands:': '🇲🇵',\n",
       " ':Norway:': '🇳🇴',\n",
       " ':OK_button:': '🆗',\n",
       " ':OK_hand:': '👌',\n",
       " ':OK_hand_dark_skin_tone:': '👌🏿',\n",
       " ':OK_hand_light_skin_tone:': '👌🏻',\n",
       " ':OK_hand_medium-dark_skin_tone:': '👌🏾',\n",
       " ':OK_hand_medium-light_skin_tone:': '👌🏼',\n",
       " ':OK_hand_medium_skin_tone:': '👌🏽',\n",
       " ':ON!_arrow:': '🔛',\n",
       " ':O_button_(blood_type):': '🅾',\n",
       " ':O_button_(blood_type)_selector:': '🅾️',\n",
       " ':Oman:': '🇴🇲',\n",
       " ':Ophiuchus:': '⛎',\n",
       " ':P_button:': '🅿',\n",
       " ':P_button_selector:': '🅿️',\n",
       " ':Pakistan:': '🇵🇰',\n",
       " ':Palau:': '🇵🇼',\n",
       " ':Palestinian_Territories:': '🇵🇸',\n",
       " ':Panama:': '🇵🇦',\n",
       " ':Papua_New_Guinea:': '🇵🇬',\n",
       " ':Paraguay:': '🇵🇾',\n",
       " ':Peru:': '🇵🇪',\n",
       " ':Philippines:': '🇵🇭',\n",
       " ':Pisces:': '♓',\n",
       " ':Pitcairn_Islands:': '🇵🇳',\n",
       " ':Poland:': '🇵🇱',\n",
       " ':Portugal:': '🇵🇹',\n",
       " ':Puerto_Rico:': '🇵🇷',\n",
       " ':Qatar:': '🇶🇦',\n",
       " ':Romania:': '🇷🇴',\n",
       " ':Russia:': '🇷🇺',\n",
       " ':Rwanda:': '🇷🇼',\n",
       " ':Réunion:': '🇷🇪',\n",
       " ':SOON_arrow:': '🔜',\n",
       " ':SOS_button:': '🆘',\n",
       " ':Sagittarius:': '♐',\n",
       " ':Samoa:': '🇼🇸',\n",
       " ':San_Marino:': '🇸🇲',\n",
       " ':Santa_Claus:': '🎅',\n",
       " ':Santa_Claus_dark_skin_tone:': '🎅🏿',\n",
       " ':Santa_Claus_light_skin_tone:': '🎅🏻',\n",
       " ':Santa_Claus_medium-dark_skin_tone:': '🎅🏾',\n",
       " ':Santa_Claus_medium-light_skin_tone:': '🎅🏼',\n",
       " ':Santa_Claus_medium_skin_tone:': '🎅🏽',\n",
       " ':Saudi_Arabia:': '🇸🇦',\n",
       " ':Scorpio:': '♏',\n",
       " ':Scotland:': '🏴\\U000e0067\\U000e0062\\U000e0073\\U000e0063\\U000e0074\\U000e007f',\n",
       " ':Senegal:': '🇸🇳',\n",
       " ':Serbia:': '🇷🇸',\n",
       " ':Seychelles:': '🇸🇨',\n",
       " ':Sierra_Leone:': '🇸🇱',\n",
       " ':Singapore:': '🇸🇬',\n",
       " ':Sint_Maarten:': '🇸🇽',\n",
       " ':Slovakia:': '🇸🇰',\n",
       " ':Slovenia:': '🇸🇮',\n",
       " ':Solomon_Islands:': '🇸🇧',\n",
       " ':Somalia:': '🇸🇴',\n",
       " ':South_Africa:': '🇿🇦',\n",
       " ':South_Georgia_&_South_Sandwich_Islands:': '🇬🇸',\n",
       " ':South_Korea:': '🇰🇷',\n",
       " ':South_Sudan:': '🇸🇸',\n",
       " ':Spain:': '🇪🇸',\n",
       " ':Sri_Lanka:': '🇱🇰',\n",
       " ':St._Barthélemy:': '🇧🇱',\n",
       " ':St._Helena:': '🇸🇭',\n",
       " ':St._Kitts_&_Nevis:': '🇰🇳',\n",
       " ':St._Lucia:': '🇱🇨',\n",
       " ':St._Martin:': '🇲🇫',\n",
       " ':St._Pierre_&_Miquelon:': '🇵🇲',\n",
       " ':St._Vincent_&_Grenadines:': '🇻🇨',\n",
       " ':Statue_of_Liberty:': '🗽',\n",
       " ':Sudan:': '🇸🇩',\n",
       " ':Suriname:': '🇸🇷',\n",
       " ':Svalbard_&_Jan_Mayen:': '🇸🇯',\n",
       " ':Swaziland:': '🇸🇿',\n",
       " ':Sweden:': '🇸🇪',\n",
       " ':Switzerland:': '🇨🇭',\n",
       " ':Syria:': '🇸🇾',\n",
       " ':São_Tomé_&_Príncipe:': '🇸🇹',\n",
       " ':T-Rex:': '🦖',\n",
       " ':TOP_arrow:': '🔝',\n",
       " ':Taiwan:': '🇹🇼',\n",
       " ':Tajikistan:': '🇹🇯',\n",
       " ':Tanzania:': '🇹🇿',\n",
       " ':Taurus:': '♉',\n",
       " ':Thailand:': '🇹🇭',\n",
       " ':Timor-Leste:': '🇹🇱',\n",
       " ':Togo:': '🇹🇬',\n",
       " ':Tokelau:': '🇹🇰',\n",
       " ':Tokyo_tower:': '🗼',\n",
       " ':Tonga:': '🇹🇴',\n",
       " ':Trinidad_&_Tobago:': '🇹🇹',\n",
       " ':Tristan_da_Cunha:': '🇹🇦',\n",
       " ':Tunisia:': '🇹🇳',\n",
       " ':Turkey:': '🇹🇷',\n",
       " ':Turkmenistan:': '🇹🇲',\n",
       " ':Turks_&_Caicos_Islands:': '🇹🇨',\n",
       " ':Tuvalu:': '🇹🇻',\n",
       " ':U.S._Outlying_Islands:': '🇺🇲',\n",
       " ':U.S._Virgin_Islands:': '🇻🇮',\n",
       " ':UP!_button:': '🆙',\n",
       " ':Uganda:': '🇺🇬',\n",
       " ':Ukraine:': '🇺🇦',\n",
       " ':United_Arab_Emirates:': '🇦🇪',\n",
       " ':United_Kingdom:': '🇬🇧',\n",
       " ':United_Nations:': '🇺🇳',\n",
       " ':United_States:': '🇺🇸',\n",
       " ':Uruguay:': '🇺🇾',\n",
       " ':Uzbekistan:': '🇺🇿',\n",
       " ':VS_button:': '🆚',\n",
       " ':Vanuatu:': '🇻🇺',\n",
       " ':Vatican_City:': '🇻🇦',\n",
       " ':Venezuela:': '🇻🇪',\n",
       " ':Vietnam:': '🇻🇳',\n",
       " ':Virgo:': '♍',\n",
       " ':Wales:': '🏴\\U000e0067\\U000e0062\\U000e0077\\U000e006c\\U000e0073\\U000e007f',\n",
       " ':Wallis_&_Futuna:': '🇼🇫',\n",
       " ':Western_Sahara:': '🇪🇭',\n",
       " ':Yemen:': '🇾🇪',\n",
       " ':Zambia:': '🇿🇲',\n",
       " ':Zimbabwe:': '🇿🇼',\n",
       " ':abacus:': '🧮',\n",
       " ':adhesive_bandage:': '\\U0001fa79',\n",
       " ':admission_tickets:': '🎟',\n",
       " ':admission_tickets_selector:': '🎟️',\n",
       " ':adult:': '🧑',\n",
       " ':adult_dark_skin_tone:': '🧑🏿',\n",
       " ':adult_light_skin_tone:': '🧑🏻',\n",
       " ':adult_medium-dark_skin_tone:': '🧑🏾',\n",
       " ':adult_medium-light_skin_tone:': '🧑🏼',\n",
       " ':adult_medium_skin_tone:': '🧑🏽',\n",
       " ':aerial_tramway:': '🚡',\n",
       " ':airplane:': '✈',\n",
       " ':airplane_arrival:': '🛬',\n",
       " ':airplane_departure:': '🛫',\n",
       " ':airplane_selector:': '✈️',\n",
       " ':alarm_clock:': '⏰',\n",
       " ':alembic:': '⚗',\n",
       " ':alembic_selector:': '⚗️',\n",
       " ':alien:': '👽',\n",
       " ':alien_monster:': '👾',\n",
       " ':ambulance:': '🚑',\n",
       " ':american_football:': '🏈',\n",
       " ':amphora:': '🏺',\n",
       " ':anchor:': '⚓',\n",
       " ':anger_symbol:': '💢',\n",
       " ':angry_face:': '😠',\n",
       " ':angry_face_with_horns:': '👿',\n",
       " ':anguished_face:': '😧',\n",
       " ':ant:': '🐜',\n",
       " ':antenna_bars:': '📶',\n",
       " ':anxious_face_with_sweat:': '😰',\n",
       " ':articulated_lorry:': '🚛',\n",
       " ':artist_palette:': '🎨',\n",
       " ':astonished_face:': '😲',\n",
       " ':atom_symbol:': '⚛',\n",
       " ':atom_symbol_selector:': '⚛️',\n",
       " ':auto_rickshaw:': '\\U0001f6fa',\n",
       " ':automobile:': '🚗',\n",
       " ':avocado:': '🥑',\n",
       " ':axe:': '\\U0001fa93',\n",
       " ':baby:': '👶',\n",
       " ':baby_angel:': '👼',\n",
       " ':baby_angel_dark_skin_tone:': '👼🏿',\n",
       " ':baby_angel_light_skin_tone:': '👼🏻',\n",
       " ':baby_angel_medium-dark_skin_tone:': '👼🏾',\n",
       " ':baby_angel_medium-light_skin_tone:': '👼🏼',\n",
       " ':baby_angel_medium_skin_tone:': '👼🏽',\n",
       " ':baby_bottle:': '🍼',\n",
       " ':baby_chick:': '🐤',\n",
       " ':baby_dark_skin_tone:': '👶🏿',\n",
       " ':baby_light_skin_tone:': '👶🏻',\n",
       " ':baby_medium-dark_skin_tone:': '👶🏾',\n",
       " ':baby_medium-light_skin_tone:': '👶🏼',\n",
       " ':baby_medium_skin_tone:': '👶🏽',\n",
       " ':baby_symbol:': '🚼',\n",
       " ':backhand_index_pointing_down:': '👇',\n",
       " ':backhand_index_pointing_down_dark_skin_tone:': '👇🏿',\n",
       " ':backhand_index_pointing_down_light_skin_tone:': '👇🏻',\n",
       " ':backhand_index_pointing_down_medium-dark_skin_tone:': '👇🏾',\n",
       " ':backhand_index_pointing_down_medium-light_skin_tone:': '👇🏼',\n",
       " ':backhand_index_pointing_down_medium_skin_tone:': '👇🏽',\n",
       " ':backhand_index_pointing_left:': '👈',\n",
       " ':backhand_index_pointing_left_dark_skin_tone:': '👈🏿',\n",
       " ':backhand_index_pointing_left_light_skin_tone:': '👈🏻',\n",
       " ':backhand_index_pointing_left_medium-dark_skin_tone:': '👈🏾',\n",
       " ':backhand_index_pointing_left_medium-light_skin_tone:': '👈🏼',\n",
       " ':backhand_index_pointing_left_medium_skin_tone:': '👈🏽',\n",
       " ':backhand_index_pointing_right:': '👉',\n",
       " ':backhand_index_pointing_right_dark_skin_tone:': '👉🏿',\n",
       " ':backhand_index_pointing_right_light_skin_tone:': '👉🏻',\n",
       " ':backhand_index_pointing_right_medium-dark_skin_tone:': '👉🏾',\n",
       " ':backhand_index_pointing_right_medium-light_skin_tone:': '👉🏼',\n",
       " ':backhand_index_pointing_right_medium_skin_tone:': '👉🏽',\n",
       " ':backhand_index_pointing_up:': '👆',\n",
       " ':backhand_index_pointing_up_dark_skin_tone:': '👆🏿',\n",
       " ':backhand_index_pointing_up_light_skin_tone:': '👆🏻',\n",
       " ':backhand_index_pointing_up_medium-dark_skin_tone:': '👆🏾',\n",
       " ':backhand_index_pointing_up_medium-light_skin_tone:': '👆🏼',\n",
       " ':backhand_index_pointing_up_medium_skin_tone:': '👆🏽',\n",
       " ':bacon:': '🥓',\n",
       " ':badger:': '🦡',\n",
       " ':badminton:': '🏸',\n",
       " ':bagel:': '🥯',\n",
       " ':baggage_claim:': '🛄',\n",
       " ':baguette_bread:': '🥖',\n",
       " ':balance_scale:': '⚖',\n",
       " ':balance_scale_selector:': '⚖️',\n",
       " ':bald:': '🦲',\n",
       " ':bald_man:': '👨\\u200d🦲',\n",
       " ':bald_woman:': '👩\\u200d🦲',\n",
       " ':ballet_shoes:': '\\U0001fa70',\n",
       " ':balloon:': '🎈',\n",
       " ':ballot_box_with_ballot:': '🗳',\n",
       " ':ballot_box_with_ballot_selector:': '🗳️',\n",
       " ':ballot_box_with_check:': '☑',\n",
       " ':banana:': '🍌',\n",
       " ':banjo:': '\\U0001fa95',\n",
       " ':bank:': '🏦',\n",
       " ':bar_chart:': '📊',\n",
       " ':barber_pole:': '💈',\n",
       " ':baseball:': '⚾',\n",
       " ':basket:': '🧺',\n",
       " ':basketball:': '🏀',\n",
       " ':bat:': '🦇',\n",
       " ':bathtub:': '🛁',\n",
       " ':battery:': '🔋',\n",
       " ':beach_with_umbrella:': '🏖',\n",
       " ':beach_with_umbrella_selector:': '🏖️',\n",
       " ':beaming_face_with_smiling_eyes:': '😁',\n",
       " ':bear_face:': '🐻',\n",
       " ':bearded_person:': '🧔',\n",
       " ':bearded_person_dark_skin_tone:': '🧔🏿',\n",
       " ':bearded_person_light_skin_tone:': '🧔🏻',\n",
       " ':bearded_person_medium-dark_skin_tone:': '🧔🏾',\n",
       " ':bearded_person_medium-light_skin_tone:': '🧔🏼',\n",
       " ':bearded_person_medium_skin_tone:': '🧔🏽',\n",
       " ':beating_heart:': '💓',\n",
       " ':bed:': '🛏',\n",
       " ':bed_selector:': '🛏️',\n",
       " ':beer_mug:': '🍺',\n",
       " ':bell:': '🔔',\n",
       " ':bell_with_slash:': '🔕',\n",
       " ':bellhop_bell:': '🛎',\n",
       " ':bellhop_bell_selector:': '🛎️',\n",
       " ':bento_box:': '🍱',\n",
       " ':beverage_box:': '\\U0001f9c3',\n",
       " ':bicycle:': '🚲',\n",
       " ':bikini:': '👙',\n",
       " ':billed_cap:': '🧢',\n",
       " ':biohazard:': '☣',\n",
       " ':biohazard_selector:': '☣️',\n",
       " ':bird:': '🐦',\n",
       " ':birthday_cake:': '🎂',\n",
       " ':black_circle:': '⚫',\n",
       " ':black_flag:': '🏴',\n",
       " ':black_heart:': '🖤',\n",
       " ':black_large_square:': '⬛',\n",
       " ':black_medium-small_square:': '◾',\n",
       " ':black_medium_square:': '◼',\n",
       " ':black_medium_square_selector:': '◼️',\n",
       " ':black_nib:': '✒',\n",
       " ':black_nib_selector:': '✒️',\n",
       " ':black_small_square:': '▪',\n",
       " ':black_small_square_selector:': '▪️',\n",
       " ':black_square_button:': '🔲',\n",
       " ':blond-haired_man:': '👱\\u200d♂️',\n",
       " ':blond-haired_man_dark_skin_tone:': '👱🏿\\u200d♂️',\n",
       " ':blond-haired_man_light_skin_tone:': '👱🏻\\u200d♂️',\n",
       " ':blond-haired_man_medium-dark_skin_tone:': '👱🏾\\u200d♂️',\n",
       " ':blond-haired_man_medium-light_skin_tone:': '👱🏼\\u200d♂️',\n",
       " ':blond-haired_man_medium_skin_tone:': '👱🏽\\u200d♂️',\n",
       " ':blond-haired_person:': '👱',\n",
       " ':blond-haired_person_dark_skin_tone:': '👱🏿',\n",
       " ':blond-haired_person_light_skin_tone:': '👱🏻',\n",
       " ':blond-haired_person_medium-dark_skin_tone:': '👱🏾',\n",
       " ':blond-haired_person_medium-light_skin_tone:': '👱🏼',\n",
       " ':blond-haired_person_medium_skin_tone:': '👱🏽',\n",
       " ':blond-haired_woman:': '👱\\u200d♀️',\n",
       " ':blond-haired_woman_dark_skin_tone:': '👱🏿\\u200d♀️',\n",
       " ':blond-haired_woman_light_skin_tone:': '👱🏻\\u200d♀️',\n",
       " ':blond-haired_woman_medium-dark_skin_tone:': '👱🏾\\u200d♀️',\n",
       " ':blond-haired_woman_medium-light_skin_tone:': '👱🏼\\u200d♀️',\n",
       " ':blond-haired_woman_medium_skin_tone:': '👱🏽\\u200d♀️',\n",
       " ':blossom:': '🌼',\n",
       " ':blowfish:': '🐡',\n",
       " ':blue_book:': '📘',\n",
       " ':blue_circle:': '🔵',\n",
       " ':blue_heart:': '💙',\n",
       " ':blue_square:': '\\U0001f7e6',\n",
       " ':boar:': '🐗',\n",
       " ':bomb:': '💣',\n",
       " ':bone:': '🦴',\n",
       " ':bookmark:': '🔖',\n",
       " ':bookmark_tabs:': '📑',\n",
       " ':books:': '📚',\n",
       " ':bottle_with_popping_cork:': '🍾',\n",
       " ':bouquet:': '💐',\n",
       " ':bow_and_arrow:': '🏹',\n",
       " ':bowl_with_spoon:': '🥣',\n",
       " ':bowling:': '🎳',\n",
       " ':boxing_glove:': '🥊',\n",
       " ':boy:': '👦',\n",
       " ':boy_dark_skin_tone:': '👦🏿',\n",
       " ':boy_light_skin_tone:': '👦🏻',\n",
       " ':boy_medium-dark_skin_tone:': '👦🏾',\n",
       " ':boy_medium-light_skin_tone:': '👦🏼',\n",
       " ':boy_medium_skin_tone:': '👦🏽',\n",
       " ':brain:': '🧠',\n",
       " ':bread:': '🍞',\n",
       " ':breast-feeding:': '🤱',\n",
       " ':breast-feeding_dark_skin_tone:': '🤱🏿',\n",
       " ':breast-feeding_light_skin_tone:': '🤱🏻',\n",
       " ':breast-feeding_medium-dark_skin_tone:': '🤱🏾',\n",
       " ':breast-feeding_medium-light_skin_tone:': '🤱🏼',\n",
       " ':breast-feeding_medium_skin_tone:': '🤱🏽',\n",
       " ':brick:': '🧱',\n",
       " ':bride_with_veil:': '👰',\n",
       " ':bride_with_veil_dark_skin_tone:': '👰🏿',\n",
       " ':bride_with_veil_light_skin_tone:': '👰🏻',\n",
       " ':bride_with_veil_medium-dark_skin_tone:': '👰🏾',\n",
       " ':bride_with_veil_medium-light_skin_tone:': '👰🏼',\n",
       " ':bride_with_veil_medium_skin_tone:': '👰🏽',\n",
       " ':bridge_at_night:': '🌉',\n",
       " ':briefcase:': '💼',\n",
       " ':briefs:': '\\U0001fa72',\n",
       " ':bright_button:': '🔆',\n",
       " ':broccoli:': '🥦',\n",
       " ':broken_heart:': '💔',\n",
       " ':broom:': '🧹',\n",
       " ':brown_circle:': '\\U0001f7e4',\n",
       " ':brown_heart:': '\\U0001f90e',\n",
       " ':brown_square:': '\\U0001f7eb',\n",
       " ':bug:': '🐛',\n",
       " ':building_construction:': '🏗',\n",
       " ':building_construction_selector:': '🏗️',\n",
       " ':bullet_train:': '🚅',\n",
       " ':burrito:': '🌯',\n",
       " ':bus:': '🚌',\n",
       " ':bus_stop:': '🚏',\n",
       " ':bust_in_silhouette:': '👤',\n",
       " ':busts_in_silhouette:': '👥',\n",
       " ':butter:': '\\U0001f9c8',\n",
       " ':butterfly:': '🦋',\n",
       " ':cactus:': '🌵',\n",
       " ':calendar:': '📅',\n",
       " ':call_me_hand:': '🤙',\n",
       " ':call_me_hand_dark_skin_tone:': '🤙🏿',\n",
       " ':call_me_hand_light_skin_tone:': '🤙🏻',\n",
       " ':call_me_hand_medium-dark_skin_tone:': '🤙🏾',\n",
       " ':call_me_hand_medium-light_skin_tone:': '🤙🏼',\n",
       " ':call_me_hand_medium_skin_tone:': '🤙🏽',\n",
       " ':camel:': '🐪',\n",
       " ':camera:': '📷',\n",
       " ':camera_with_flash:': '📸',\n",
       " ':camping:': '🏕',\n",
       " ':camping_selector:': '🏕️',\n",
       " ':candle:': '🕯',\n",
       " ':candle_selector:': '🕯️',\n",
       " ':candy:': '🍬',\n",
       " ':canned_food:': '🥫',\n",
       " ':canoe:': '🛶',\n",
       " ':card_file_box:': '🗃',\n",
       " ':card_file_box_selector:': '🗃️',\n",
       " ':card_index:': '📇',\n",
       " ':card_index_dividers:': '🗂',\n",
       " ':card_index_dividers_selector:': '🗂️',\n",
       " ':carousel_horse:': '🎠',\n",
       " ':carp_streamer:': '🎏',\n",
       " ':carrot:': '🥕',\n",
       " ':castle:': '🏰',\n",
       " ':cat:': '🐈',\n",
       " ':cat_face:': '🐱',\n",
       " ':cat_face_with_tears_of_joy:': '😹',\n",
       " ':cat_face_with_wry_smile:': '😼',\n",
       " ':chains:': '⛓',\n",
       " ':chains_selector:': '⛓️',\n",
       " ':chair:': '\\U0001fa91',\n",
       " ':chart_decreasing:': '📉',\n",
       " ':chart_increasing:': '📈',\n",
       " ':chart_increasing_with_yen:': '💹',\n",
       " ':check_box_with_check:': '☑️',\n",
       " ':check_mark:': '✔️',\n",
       " ':cheese_wedge:': '🧀',\n",
       " ':chequered_flag:': '🏁',\n",
       " ':cherries:': '🍒',\n",
       " ':cherry_blossom:': '🌸',\n",
       " ':chess_pawn:': '♟',\n",
       " ':chess_pawn_selector:': '♟️',\n",
       " ':chestnut:': '🌰',\n",
       " ':chicken:': '🐔',\n",
       " ':child:': '🧒',\n",
       " ':child_dark_skin_tone:': '🧒🏿',\n",
       " ':child_light_skin_tone:': '🧒🏻',\n",
       " ':child_medium-dark_skin_tone:': '🧒🏾',\n",
       " ':child_medium-light_skin_tone:': '🧒🏼',\n",
       " ':child_medium_skin_tone:': '🧒🏽',\n",
       " ':children_crossing:': '🚸',\n",
       " ':chipmunk:': '🐿',\n",
       " ':chipmunk_selector:': '🐿️',\n",
       " ':chocolate_bar:': '🍫',\n",
       " ':chopsticks:': '🥢',\n",
       " ':church:': '⛪',\n",
       " ':cigarette:': '🚬',\n",
       " ':cinema:': '🎦',\n",
       " ':circled_M:': 'Ⓜ',\n",
       " ':circled_M_selector:': 'Ⓜ️',\n",
       " ':circus_tent:': '🎪',\n",
       " ':cityscape:': '🏙',\n",
       " ':cityscape_at_dusk:': '🌆',\n",
       " ':cityscape_selector:': '🏙️',\n",
       " ':clamp:': '🗜',\n",
       " ':clamp_selector:': '🗜️',\n",
       " ':clapper_board:': '🎬',\n",
       " ':clapping_hands:': '👏',\n",
       " ':clapping_hands_dark_skin_tone:': '👏🏿',\n",
       " ':clapping_hands_light_skin_tone:': '👏🏻',\n",
       " ':clapping_hands_medium-dark_skin_tone:': '👏🏾',\n",
       " ':clapping_hands_medium-light_skin_tone:': '👏🏼',\n",
       " ':clapping_hands_medium_skin_tone:': '👏🏽',\n",
       " ':classical_building:': '🏛',\n",
       " ':classical_building_selector:': '🏛️',\n",
       " ':clinking_beer_mugs:': '🍻',\n",
       " ':clinking_glasses:': '🥂',\n",
       " ':clipboard:': '📋',\n",
       " ':clockwise_vertical_arrows:': '🔃',\n",
       " ':closed_book:': '📕',\n",
       " ':closed_mailbox_with_lowered_flag:': '📪',\n",
       " ':closed_mailbox_with_raised_flag:': '📫',\n",
       " ':closed_umbrella:': '🌂',\n",
       " ':cloud:': '☁',\n",
       " ':cloud_selector:': '☁️',\n",
       " ':cloud_with_lightning:': '🌩',\n",
       " ':cloud_with_lightning_and_rain:': '⛈',\n",
       " ':cloud_with_lightning_and_rain_selector:': '⛈️',\n",
       " ':cloud_with_lightning_selector:': '🌩️',\n",
       " ':cloud_with_rain:': '🌧',\n",
       " ':cloud_with_rain_selector:': '🌧️',\n",
       " ':cloud_with_snow:': '🌨',\n",
       " ':cloud_with_snow_selector:': '🌨️',\n",
       " ':clown_face:': '🤡',\n",
       " ':club_suit:': '♣',\n",
       " ':club_suit_selector:': '♣️',\n",
       " ':clutch_bag:': '👝',\n",
       " ':coat:': '🧥',\n",
       " ':cocktail_glass:': '🍸',\n",
       " ':coconut:': '🥥',\n",
       " ':coffin:': '⚰',\n",
       " ':coffin_selector:': '⚰️',\n",
       " ':cold_face:': '🥶',\n",
       " ':collision:': '💥',\n",
       " ':comet:': '☄',\n",
       " ':comet_selector:': '☄️',\n",
       " ':compass:': '🧭',\n",
       " ':computer_disk:': '💽',\n",
       " ':computer_mouse:': '🖱',\n",
       " ':computer_mouse_selector:': '🖱️',\n",
       " ':confetti_ball:': '🎊',\n",
       " ':confounded_face:': '😖',\n",
       " ':confused_face:': '😕',\n",
       " ':construction:': '🚧',\n",
       " ':construction_worker:': '👷',\n",
       " ':construction_worker_dark_skin_tone:': '👷🏿',\n",
       " ':construction_worker_light_skin_tone:': '👷🏻',\n",
       " ':construction_worker_medium-dark_skin_tone:': '👷🏾',\n",
       " ':construction_worker_medium-light_skin_tone:': '👷🏼',\n",
       " ':construction_worker_medium_skin_tone:': '👷🏽',\n",
       " ':control_knobs:': '🎛',\n",
       " ':control_knobs_selector:': '🎛️',\n",
       " ':convenience_store:': '🏪',\n",
       " ':cooked_rice:': '🍚',\n",
       " ':cookie:': '🍪',\n",
       " ':cooking:': '🍳',\n",
       " ':copyright:': '©',\n",
       " ':copyright_selector:': '©️',\n",
       " ':couch_and_lamp:': '🛋',\n",
       " ':couch_and_lamp_selector:': '🛋️',\n",
       " ':counterclockwise_arrows_button:': '🔄',\n",
       " ':couple_with_heart-man-man:': '👨\\u200d❤\\u200d👨',\n",
       " ':couple_with_heart-woman-man:': '👩\\u200d❤\\u200d👨',\n",
       " ':couple_with_heart-woman-woman:': '👩\\u200d❤\\u200d👩',\n",
       " ':couple_with_heart:': '💑',\n",
       " ':couple_with_heart_man_man:': '👨\\u200d❤️\\u200d👨',\n",
       " ':couple_with_heart_woman_man:': '👩\\u200d❤️\\u200d👨',\n",
       " ':couple_with_heart_woman_woman:': '👩\\u200d❤️\\u200d👩',\n",
       " ':cow:': '🐄',\n",
       " ':cow_face:': '🐮',\n",
       " ':cowboy_hat_face:': '🤠',\n",
       " ':crab:': '🦀',\n",
       " ':crayon:': '🖍',\n",
       " ':crayon_selector:': '🖍️',\n",
       " ':credit_card:': '💳',\n",
       " ':crescent_moon:': '🌙',\n",
       " ':cricket:': '🦗',\n",
       " ':cricket_game:': '🏏',\n",
       " ':crocodile:': '🐊',\n",
       " ':croissant:': '🥐',\n",
       " ':cross_mark:': '❌',\n",
       " ':cross_mark_button:': '❎',\n",
       " ':crossed_fingers:': '🤞',\n",
       " ':crossed_fingers_dark_skin_tone:': '🤞🏿',\n",
       " ':crossed_fingers_light_skin_tone:': '🤞🏻',\n",
       " ':crossed_fingers_medium-dark_skin_tone:': '🤞🏾',\n",
       " ':crossed_fingers_medium-light_skin_tone:': '🤞🏼',\n",
       " ':crossed_fingers_medium_skin_tone:': '🤞🏽',\n",
       " ':crossed_flags:': '🎌',\n",
       " ':crossed_swords:': '⚔',\n",
       " ':crossed_swords_selector:': '⚔️',\n",
       " ':crown:': '👑',\n",
       " ':crying_cat_face:': '😿',\n",
       " ':crying_face:': '😢',\n",
       " ':crystal_ball:': '🔮',\n",
       " ':cucumber:': '🥒',\n",
       " ':cup_with_straw:': '🥤',\n",
       " ':cupcake:': '🧁',\n",
       " ':curling_stone:': '🥌',\n",
       " ':curly-haired_man:': '👨\\u200d🦱',\n",
       " ':curly-haired_woman:': '👩\\u200d🦱',\n",
       " ':curly_hair:': '🦱',\n",
       " ':curly_loop:': '➰',\n",
       " ':currency_exchange:': '💱',\n",
       " ':curry_rice:': '🍛',\n",
       " ':custard:': '🍮',\n",
       " ':customs:': '🛃',\n",
       " ':cut_of_meat:': '🥩',\n",
       " ':cyclone:': '🌀',\n",
       " ':dagger:': '🗡',\n",
       " ':dagger_selector:': '🗡️',\n",
       " ':dango:': '🍡',\n",
       " ':dark_skin_tone:': '🏿',\n",
       " ':dashing_away:': '💨',\n",
       " ':deaf_man-dark_skin_tone:': '\\U0001f9cf🏿\\u200d♂',\n",
       " ':deaf_man-dark_skin_tone_selector:': '\\U0001f9cf🏿\\u200d♂️',\n",
       " ':deaf_man-light_skin_tone:': '\\U0001f9cf🏻\\u200d♂',\n",
       " ':deaf_man-light_skin_tone_selector:': '\\U0001f9cf🏻\\u200d♂️',\n",
       " ':deaf_man-medium-dark_skin_tone:': '\\U0001f9cf🏾\\u200d♂',\n",
       " ':deaf_man-medium-dark_skin_tone_selector:': '\\U0001f9cf🏾\\u200d♂️',\n",
       " ':deaf_man-medium-light_skin_tone:': '\\U0001f9cf🏼\\u200d♂',\n",
       " ':deaf_man-medium-light_skin_tone_selector:': '\\U0001f9cf🏼\\u200d♂️',\n",
       " ':deaf_man-medium_skin_tone:': '\\U0001f9cf🏽\\u200d♂',\n",
       " ':deaf_man-medium_skin_tone_selector:': '\\U0001f9cf🏽\\u200d♂️',\n",
       " ':deaf_man:': '\\U0001f9cf\\u200d♂',\n",
       " ':deaf_man_selector:': '\\U0001f9cf\\u200d♂️',\n",
       " ':deaf_person-dark_skin_tone:': '\\U0001f9cf🏿',\n",
       " ':deaf_person-light_skin_tone:': '\\U0001f9cf🏻',\n",
       " ':deaf_person-medium-dark_skin_tone:': '\\U0001f9cf🏾',\n",
       " ':deaf_person-medium-light_skin_tone:': '\\U0001f9cf🏼',\n",
       " ':deaf_person-medium_skin_tone:': '\\U0001f9cf🏽',\n",
       " ':deaf_person:': '\\U0001f9cf',\n",
       " ':deaf_woman-dark_skin_tone:': '\\U0001f9cf🏿\\u200d♀',\n",
       " ':deaf_woman-dark_skin_tone_selector:': '\\U0001f9cf🏿\\u200d♀️',\n",
       " ':deaf_woman-light_skin_tone:': '\\U0001f9cf🏻\\u200d♀',\n",
       " ':deaf_woman-light_skin_tone_selector:': '\\U0001f9cf🏻\\u200d♀️',\n",
       " ':deaf_woman-medium-dark_skin_tone:': '\\U0001f9cf🏾\\u200d♀',\n",
       " ':deaf_woman-medium-dark_skin_tone_selector:': '\\U0001f9cf🏾\\u200d♀️',\n",
       " ':deaf_woman-medium-light_skin_tone:': '\\U0001f9cf🏼\\u200d♀',\n",
       " ':deaf_woman-medium-light_skin_tone_selector:': '\\U0001f9cf🏼\\u200d♀️',\n",
       " ':deaf_woman-medium_skin_tone:': '\\U0001f9cf🏽\\u200d♀',\n",
       " ':deaf_woman-medium_skin_tone_selector:': '\\U0001f9cf🏽\\u200d♀️',\n",
       " ':deaf_woman:': '\\U0001f9cf\\u200d♀',\n",
       " ':deaf_woman_selector:': '\\U0001f9cf\\u200d♀️',\n",
       " ':deciduous_tree:': '🌳',\n",
       " ':deer:': '🦌',\n",
       " ':delivery_truck:': '🚚',\n",
       " ':department_store:': '🏬',\n",
       " ':derelict_house:': '🏚',\n",
       " ':derelict_house_selector:': '🏚️',\n",
       " ':desert:': '🏜',\n",
       " ':desert_island:': '🏝',\n",
       " ':desert_island_selector:': '🏝️',\n",
       " ':desert_selector:': '🏜️',\n",
       " ':desktop_computer:': '🖥',\n",
       " ':desktop_computer_selector:': '🖥️',\n",
       " ':detective:': '🕵',\n",
       " ':detective_dark_skin_tone:': '🕵🏿',\n",
       " ':detective_light_skin_tone:': '🕵🏻',\n",
       " ':detective_medium-dark_skin_tone:': '🕵🏾',\n",
       " ':detective_medium-light_skin_tone:': '🕵🏼',\n",
       " ':detective_medium_skin_tone:': '🕵🏽',\n",
       " ':detective_selector:': '🕵️',\n",
       " ':diamond_suit:': '♦',\n",
       " ':diamond_suit_selector:': '♦️',\n",
       " ':diamond_with_a_dot:': '💠',\n",
       " ':dim_button:': '🔅',\n",
       " ':direct_hit:': '🎯',\n",
       " ':disappointed_face:': '😞',\n",
       " ':diving_mask:': '\\U0001f93f',\n",
       " ':diya_lamp:': '\\U0001fa94',\n",
       " ':dizzy:': '💫',\n",
       " ':dizzy_face:': '😵',\n",
       " ':dna:': '🧬',\n",
       " ':dog:': '🐕',\n",
       " ':dog_face:': '🐶',\n",
       " ':dollar_banknote:': '💵',\n",
       " ':dolphin:': '🐬',\n",
       " ':door:': '🚪',\n",
       " ':dotted_six-pointed_star:': '🔯',\n",
       " ':double_curly_loop:': '➿',\n",
       " ':double_exclamation_mark:': '‼',\n",
       " ':double_exclamation_mark_selector:': '‼️',\n",
       " ':doughnut:': '🍩',\n",
       " ':dove:': '🕊',\n",
       " ':dove_selector:': '🕊️',\n",
       " ':down-left_arrow:': '↙',\n",
       " ':down-left_arrow_selector:': '↙️',\n",
       " ':down-right_arrow:': '↘',\n",
       " ':down-right_arrow_selector:': '↘️',\n",
       " ':down_arrow:': '⬇',\n",
       " ':down_arrow_selector:': '⬇️',\n",
       " ':downcast_face_with_sweat:': '😓',\n",
       " ':downwards_button:': '🔽',\n",
       " ':dragon:': '🐉',\n",
       " ':dragon_face:': '🐲',\n",
       " ':dress:': '👗',\n",
       " ':drooling_face:': '🤤',\n",
       " ':drop_of_blood:': '\\U0001fa78',\n",
       " ':droplet:': '💧',\n",
       " ':drum:': '🥁',\n",
       " ':duck:': '🦆',\n",
       " ':dumpling:': '🥟',\n",
       " ':dvd:': '📀',\n",
       " ':e-mail:': '📧',\n",
       " ':eagle:': '🦅',\n",
       " ':ear:': '👂',\n",
       " ':ear_dark_skin_tone:': '👂🏿',\n",
       " ':ear_light_skin_tone:': '👂🏻',\n",
       " ':ear_medium-dark_skin_tone:': '👂🏾',\n",
       " ':ear_medium-light_skin_tone:': '👂🏼',\n",
       " ':ear_medium_skin_tone:': '👂🏽',\n",
       " ':ear_of_corn:': '🌽',\n",
       " ':ear_with_hearing_aid-dark_skin_tone:': '\\U0001f9bb🏿',\n",
       " ':ear_with_hearing_aid-light_skin_tone:': '\\U0001f9bb🏻',\n",
       " ':ear_with_hearing_aid-medium-dark_skin_tone:': '\\U0001f9bb🏾',\n",
       " ':ear_with_hearing_aid-medium-light_skin_tone:': '\\U0001f9bb🏼',\n",
       " ':ear_with_hearing_aid-medium_skin_tone:': '\\U0001f9bb🏽',\n",
       " ':ear_with_hearing_aid:': '\\U0001f9bb',\n",
       " ':egg:': '🥚',\n",
       " ':eggplant:': '🍆',\n",
       " ':eight-pointed_star:': '✴',\n",
       " ':eight-pointed_star_selector:': '✴️',\n",
       " ':eight-spoked_asterisk:': '✳',\n",
       " ':eight-spoked_asterisk_selector:': '✳️',\n",
       " ':eight-thirty:': '🕣',\n",
       " ':eight_o’clock:': '🕗',\n",
       " ':eject_button:': '⏏',\n",
       " ':eject_button_selector:': '⏏️',\n",
       " ':electric_plug:': '🔌',\n",
       " ':elephant:': '🐘',\n",
       " ':eleven-thirty:': '🕦',\n",
       " ':eleven_o’clock:': '🕚',\n",
       " ':elf:': '🧝',\n",
       " ':elf_dark_skin_tone:': '🧝🏿',\n",
       " ':elf_light_skin_tone:': '🧝🏻',\n",
       " ':elf_medium-dark_skin_tone:': '🧝🏾',\n",
       " ':elf_medium-light_skin_tone:': '🧝🏼',\n",
       " ':elf_medium_skin_tone:': '🧝🏽',\n",
       " ':envelope:': '✉',\n",
       " ':envelope_selector:': '✉️',\n",
       " ':envelope_with_arrow:': '📩',\n",
       " ':euro_banknote:': '💶',\n",
       " ':evergreen_tree:': '🌲',\n",
       " ':ewe:': '🐑',\n",
       " ':exclamation_mark:': '❗',\n",
       " ':exclamation_question_mark:': '⁉',\n",
       " ':exclamation_question_mark_selector:': '⁉️',\n",
       " ':exploding_head:': '🤯',\n",
       " ':expressionless_face:': '😑',\n",
       " ':eye:': '👁',\n",
       " ':eye_in_speech_bubble:': '👁\\u200d🗨',\n",
       " ':eye_in_speech_bubble_2:': '👁\\u200d🗨️',\n",
       " ':eye_in_speech_bubble_3:': '👁️\\u200d🗨️',\n",
       " ':eye_in_speech_bubble_selector:': '👁️\\u200d🗨',\n",
       " ':eye_selector:': '👁️',\n",
       " ':eyes:': '👀',\n",
       " ':face_blowing_a_kiss:': '😘',\n",
       " ':face_savoring_food:': '😋',\n",
       " ':face_screaming_in_fear:': '😱',\n",
       " ':face_vomiting:': '🤮',\n",
       " ':face_with_hand_over_mouth:': '🤭',\n",
       " ':face_with_head-bandage:': '🤕',\n",
       " ':face_with_medical_mask:': '😷',\n",
       " ':face_with_monocle:': '🧐',\n",
       " ':face_with_open_mouth:': '😮',\n",
       " ':face_with_raised_eyebrow:': '🤨',\n",
       " ':face_with_rolling_eyes:': '🙄',\n",
       " ':face_with_steam_from_nose:': '😤',\n",
       " ':face_with_symbols_on_mouth:': '🤬',\n",
       " ':face_with_tears_of_joy:': '😂',\n",
       " ':face_with_thermometer:': '🤒',\n",
       " ':face_with_tongue:': '😛',\n",
       " ':face_without_mouth:': '😶',\n",
       " ':factory:': '🏭',\n",
       " ':fairy:': '🧚',\n",
       " ':fairy_dark_skin_tone:': '🧚🏿',\n",
       " ':fairy_light_skin_tone:': '🧚🏻',\n",
       " ':fairy_medium-dark_skin_tone:': '🧚🏾',\n",
       " ':fairy_medium-light_skin_tone:': '🧚🏼',\n",
       " ':fairy_medium_skin_tone:': '🧚🏽',\n",
       " ':falafel:': '\\U0001f9c6',\n",
       " ':fallen_leaf:': '🍂',\n",
       " ':family:': '👪',\n",
       " ':family_man_boy:': '👨\\u200d👦',\n",
       " ':family_man_boy_boy:': '👨\\u200d👦\\u200d👦',\n",
       " ':family_man_girl:': '👨\\u200d👧',\n",
       " ':family_man_girl_boy:': '👨\\u200d👧\\u200d👦',\n",
       " ':family_man_girl_girl:': '👨\\u200d👧\\u200d👧',\n",
       " ':family_man_man_boy:': '👨\\u200d👨\\u200d👦',\n",
       " ':family_man_man_boy_boy:': '👨\\u200d👨\\u200d👦\\u200d👦',\n",
       " ':family_man_man_girl:': '👨\\u200d👨\\u200d👧',\n",
       " ':family_man_man_girl_boy:': '👨\\u200d👨\\u200d👧\\u200d👦',\n",
       " ':family_man_man_girl_girl:': '👨\\u200d👨\\u200d👧\\u200d👧',\n",
       " ':family_man_woman_boy:': '👨\\u200d👩\\u200d👦',\n",
       " ':family_man_woman_boy_boy:': '👨\\u200d👩\\u200d👦\\u200d👦',\n",
       " ':family_man_woman_girl:': '👨\\u200d👩\\u200d👧',\n",
       " ':family_man_woman_girl_boy:': '👨\\u200d👩\\u200d👧\\u200d👦',\n",
       " ':family_man_woman_girl_girl:': '👨\\u200d👩\\u200d👧\\u200d👧',\n",
       " ':family_woman_boy:': '👩\\u200d👦',\n",
       " ':family_woman_boy_boy:': '👩\\u200d👦\\u200d👦',\n",
       " ':family_woman_girl:': '👩\\u200d👧',\n",
       " ':family_woman_girl_boy:': '👩\\u200d👧\\u200d👦',\n",
       " ':family_woman_girl_girl:': '👩\\u200d👧\\u200d👧',\n",
       " ':family_woman_woman_boy:': '👩\\u200d👩\\u200d👦',\n",
       " ':family_woman_woman_boy_boy:': '👩\\u200d👩\\u200d👦\\u200d👦',\n",
       " ':family_woman_woman_girl:': '👩\\u200d👩\\u200d👧',\n",
       " ':family_woman_woman_girl_boy:': '👩\\u200d👩\\u200d👧\\u200d👦',\n",
       " ':family_woman_woman_girl_girl:': '👩\\u200d👩\\u200d👧\\u200d👧',\n",
       " ':fast-forward_button:': '⏩',\n",
       " ':fast_down_button:': '⏬',\n",
       " ':fast_reverse_button:': '⏪',\n",
       " ':fast_up_button:': '⏫',\n",
       " ':fax_machine:': '📠',\n",
       " ':fearful_face:': '😨',\n",
       " ':female_sign:': '♀',\n",
       " ':female_sign_selector:': '♀️',\n",
       " ':ferris_wheel:': '🎡',\n",
       " ':ferry:': '⛴',\n",
       " ':ferry_selector:': '⛴️',\n",
       " ':field_hockey:': '🏑',\n",
       " ':file_cabinet:': '🗄',\n",
       " ':file_cabinet_selector:': '🗄️',\n",
       " ':file_folder:': '📁',\n",
       " ':film_frames:': '🎞',\n",
       " ':film_frames_selector:': '🎞️',\n",
       " ':film_projector:': '📽',\n",
       " ':film_projector_selector:': '📽️',\n",
       " ':fire:': '🔥',\n",
       " ':fire_engine:': '🚒',\n",
       " ':fire_extinguisher:': '🧯',\n",
       " ':firecracker:': '🧨',\n",
       " ':fireworks:': '🎆',\n",
       " ':first_quarter_moon:': '🌓',\n",
       " ':first_quarter_moon_face:': '🌛',\n",
       " ':fish:': '🐟',\n",
       " ':fish_cake_with_swirl:': '🍥',\n",
       " ':fishing_pole:': '🎣',\n",
       " ':five-thirty:': '🕠',\n",
       " ':five_o’clock:': '🕔',\n",
       " ':flag_in_hole:': '⛳',\n",
       " ':flamingo:': '\\U0001f9a9',\n",
       " ':flashlight:': '🔦',\n",
       " ':flat_shoe:': '🥿',\n",
       " ':fleur-de-lis:': '⚜',\n",
       " ':fleur-de-lis_selector:': '⚜️',\n",
       " ':flexed_biceps:': '💪',\n",
       " ':flexed_biceps_dark_skin_tone:': '💪🏿',\n",
       " ':flexed_biceps_light_skin_tone:': '💪🏻',\n",
       " ':flexed_biceps_medium-dark_skin_tone:': '💪🏾',\n",
       " ':flexed_biceps_medium-light_skin_tone:': '💪🏼',\n",
       " ':flexed_biceps_medium_skin_tone:': '💪🏽',\n",
       " ':floppy_disk:': '💾',\n",
       " ':flower_playing_cards:': '🎴',\n",
       " ':flushed_face:': '😳',\n",
       " ...}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji.EMOJI_UNICODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('D:\\Data Sets\\emoji_train.csv',header=None)\n",
    "test=pd.read_csv('D:\\Data Sets\\emoji_test.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>never talk to me again</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am proud of your achievements</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is the worst day in my life</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miss you so much</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food is life</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0  1   2     3\n",
       "0           never talk to me again  3 NaN   NaN\n",
       "1  I am proud of your achievements  2 NaN   NaN\n",
       "2   It is the worst day in my life  3 NaN   NaN\n",
       "3                 Miss you so much  0 NaN   [0]\n",
       "4                     food is life  4 NaN   NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dict = { 0 : \":heart:\", 1 : \":baseball:\", 2 : \":smile:\", 3 : \":disappointed:\", 4 : \":fork_and_knife:\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ❤\n",
      "1 ⚾\n",
      "2 😄\n",
      "3 😞\n",
      "4 🍴\n"
     ]
    }
   ],
   "source": [
    "for ix in emoji_dict.keys():\n",
    "    print (ix,end=\" \")\n",
    "    print (emoji.emojize(emoji_dict[ix], use_aliases=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132,) (132,) (56,) (56,)\n"
     ]
    }
   ],
   "source": [
    "X_train = train[0]\n",
    "Y_train = train[1]\n",
    "\n",
    "X_test = test[0]\n",
    "Y_test = test[1]\n",
    "\n",
    "print (X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "never talk to me again 😞\n",
      "I am proud of your achievements 😄\n",
      "It is the worst day in my life 😞\n",
      "Miss you so much ❤\n",
      "food is life 🍴\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print( X_train[i],emoji.emojize( emoji_dict[(Y_train[i])], use_aliases=True ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('D:\\Data Sets\\glove.6B.50d.txt',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index={}\n",
    "\n",
    "for line in f:\n",
    "    values=line.split()\n",
    "    word=values[0]\n",
    "    coef=np.asarray(values[1:],dtype='float')\n",
    "    \n",
    "    embeddings_index[word]=coef\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.4295e-01, -4.2946e-01, -5.4277e-01, -1.0307e+00,  1.2056e+00,\n",
       "       -2.7174e-01, -6.3561e-01, -1.5065e-02,  3.7856e-01,  4.6474e-02,\n",
       "       -1.3102e-01,  6.0500e-01,  1.6391e+00,  2.3940e-01,  1.2128e+00,\n",
       "        8.3178e-01,  7.3893e-01,  1.5200e-01, -1.4175e-01, -8.8384e-01,\n",
       "        2.0829e-02, -3.2545e-01,  1.8035e+00,  1.0045e+00,  5.8484e-01,\n",
       "       -6.2031e-01, -4.3296e-01,  2.3562e-01,  1.3027e+00, -8.1264e-01,\n",
       "        2.3158e+00,  1.1030e+00, -6.0608e-01,  1.0101e+00, -2.2426e-01,\n",
       "        1.8908e-02, -1.0931e-01,  3.8350e-01,  7.7362e-01, -8.1927e-02,\n",
       "       -3.4040e-01, -1.5143e-03, -5.6640e-02,  8.7359e-01,  1.4805e+00,\n",
       "        6.9421e-01, -3.0966e-01, -9.0826e-01,  3.7277e-03,  8.4550e-01])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index[\"eat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_output(x):\n",
    "    maxlen=10\n",
    "    emb_dim=50\n",
    "    embedding_out=np.zeros((x.shape[0],maxlen,emb_dim))\n",
    "    \n",
    "    for ix in range (x.shape[0]):\n",
    "        x[ix]=x[ix].split()\n",
    "        \n",
    "        for ij in range(len(x[ix])):\n",
    "            try:\n",
    "                embedding_out[ix][ij]=embeddings_index[x[ix][ij].lower()]\n",
    "            except:\n",
    "                embedding_out[ix][ij]=np.zeros((50,))\n",
    "                \n",
    "    return embedding_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayan\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "embeddings_matrix_train=embedding_output(X_train)\n",
    "embeddings_matrix_test=embedding_output(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 10, 50)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_matrix_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 10, 50)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_matrix_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=to_categorical(Y_train,num_classes=5)\n",
    "Y_test=to_categorical(Y_test,num_classes=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model\n",
    "## Using RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 10, 64)            29440     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 62,789\n",
      "Trainable params: 62,789\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(LSTM(64,input_shape=(10,50),return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(64,return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1882 - accuracy: 0.9688\n",
      "Epoch 00001: val_loss improved from inf to 0.13366, saving model to best_emoji_model.h5\n",
      "2/2 [==============================] - 1s 541ms/step - loss: 0.2082 - accuracy: 0.9524 - val_loss: 0.1337 - val_accuracy: 0.9630\n",
      "Epoch 2/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2445 - accuracy: 0.9531\n",
      "Epoch 00002: val_loss improved from 0.13366 to 0.09981, saving model to best_emoji_model.h5\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.1946 - accuracy: 0.9524 - val_loss: 0.0998 - val_accuracy: 1.0000\n",
      "Epoch 3/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1986 - accuracy: 0.9688\n",
      "Epoch 00003: val_loss improved from 0.09981 to 0.07280, saving model to best_emoji_model.h5\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1919 - accuracy: 0.9524 - val_loss: 0.0728 - val_accuracy: 1.0000\n",
      "Epoch 4/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1279 - accuracy: 0.9688\n",
      "Epoch 00004: val_loss improved from 0.07280 to 0.06208, saving model to best_emoji_model.h5\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.1454 - accuracy: 0.9619 - val_loss: 0.0621 - val_accuracy: 1.0000\n",
      "Epoch 5/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0874 - accuracy: 0.9844\n",
      "Epoch 00005: val_loss did not improve from 0.06208\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1010 - accuracy: 0.9810 - val_loss: 0.0708 - val_accuracy: 0.9630\n",
      "Epoch 6/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1392 - accuracy: 0.9688\n",
      "Epoch 00006: val_loss did not improve from 0.06208\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1299 - accuracy: 0.9714 - val_loss: 0.0839 - val_accuracy: 0.9630\n",
      "Epoch 7/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1777 - accuracy: 0.9531\n",
      "Epoch 00007: val_loss improved from 0.06208 to 0.06121, saving model to best_emoji_model.h5\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.1358 - accuracy: 0.9714 - val_loss: 0.0612 - val_accuracy: 1.0000\n",
      "Epoch 8/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0731 - accuracy: 1.0000\n",
      "Epoch 00008: val_loss improved from 0.06121 to 0.04277, saving model to best_emoji_model.h5\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.1070 - accuracy: 0.9905 - val_loss: 0.0428 - val_accuracy: 1.0000\n",
      "Epoch 9/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0950 - accuracy: 0.9844\n",
      "Epoch 00009: val_loss improved from 0.04277 to 0.03847, saving model to best_emoji_model.h5\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0891 - accuracy: 0.9905 - val_loss: 0.0385 - val_accuracy: 1.0000\n",
      "Epoch 10/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1129 - accuracy: 0.9844\n",
      "Epoch 00010: val_loss improved from 0.03847 to 0.03798, saving model to best_emoji_model.h5\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.1010 - accuracy: 0.9905 - val_loss: 0.0380 - val_accuracy: 1.0000\n",
      "Epoch 11/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0902 - accuracy: 1.0000\n",
      "Epoch 00011: val_loss improved from 0.03798 to 0.03777, saving model to best_emoji_model.h5\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0947 - accuracy: 0.9905 - val_loss: 0.0378 - val_accuracy: 1.0000\n",
      "Epoch 12/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0753 - accuracy: 1.0000\n",
      "Epoch 00012: val_loss improved from 0.03777 to 0.03709, saving model to best_emoji_model.h5\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0698 - accuracy: 1.0000 - val_loss: 0.0371 - val_accuracy: 1.0000\n",
      "Epoch 13/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0682 - accuracy: 1.0000\n",
      "Epoch 00013: val_loss improved from 0.03709 to 0.03697, saving model to best_emoji_model.h5\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0739 - accuracy: 0.9905 - val_loss: 0.0370 - val_accuracy: 1.0000\n",
      "Epoch 14/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0735 - accuracy: 0.9688\n",
      "Epoch 00014: val_loss did not improve from 0.03697\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0682 - accuracy: 0.9810 - val_loss: 0.0393 - val_accuracy: 1.0000\n",
      "Epoch 15/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0808 - accuracy: 1.0000\n",
      "Epoch 00015: val_loss did not improve from 0.03697\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0739 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 1.0000\n",
      "Epoch 16/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0728 - accuracy: 0.9844\n",
      "Epoch 00016: val_loss improved from 0.03697 to 0.03474, saving model to best_emoji_model.h5\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.0701 - accuracy: 0.9905 - val_loss: 0.0347 - val_accuracy: 1.0000\n",
      "Epoch 17/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0506 - accuracy: 1.0000\n",
      "Epoch 00017: val_loss improved from 0.03474 to 0.02989, saving model to best_emoji_model.h5\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0450 - accuracy: 1.0000 - val_loss: 0.0299 - val_accuracy: 1.0000\n",
      "Epoch 18/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0563 - accuracy: 1.0000\n",
      "Epoch 00018: val_loss improved from 0.02989 to 0.02807, saving model to best_emoji_model.h5\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0573 - accuracy: 1.0000 - val_loss: 0.0281 - val_accuracy: 1.0000\n",
      "Epoch 19/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0805 - accuracy: 0.9688\n",
      "Epoch 00019: val_loss did not improve from 0.02807\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0585 - accuracy: 0.9810 - val_loss: 0.0298 - val_accuracy: 1.0000\n",
      "Epoch 20/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0436 - accuracy: 1.0000\n",
      "Epoch 00020: val_loss did not improve from 0.02807\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0488 - accuracy: 1.0000 - val_loss: 0.0336 - val_accuracy: 1.0000\n",
      "Epoch 21/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0492 - accuracy: 1.0000\n",
      "Epoch 00021: val_loss did not improve from 0.02807\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0373 - accuracy: 1.0000 - val_loss: 0.0349 - val_accuracy: 1.0000\n",
      "Epoch 22/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0604 - accuracy: 0.9844\n",
      "Epoch 00022: val_loss did not improve from 0.02807\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0599 - accuracy: 0.9905 - val_loss: 0.0358 - val_accuracy: 1.0000\n",
      "Epoch 23/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0639 - accuracy: 1.0000\n",
      "Epoch 00023: val_loss did not improve from 0.02807\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0546 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 1.0000\n",
      "Epoch 24/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0303 - accuracy: 1.0000\n",
      "Epoch 00024: val_loss did not improve from 0.02807\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 1.0000\n",
      "Epoch 25/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0268 - accuracy: 1.0000\n",
      "Epoch 00025: val_loss improved from 0.02807 to 0.02627, saving model to best_emoji_model.h5\n",
      "2/2 [==============================] - 1s 322ms/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.0263 - val_accuracy: 1.0000\n",
      "Epoch 26/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0188 - accuracy: 1.0000\n",
      "Epoch 00026: val_loss improved from 0.02627 to 0.01713, saving model to best_emoji_model.h5\n",
      "2/2 [==============================] - 0s 250ms/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 1.0000\n",
      "Epoch 27/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0140 - accuracy: 1.0000\n",
      "Epoch 00027: val_loss improved from 0.01713 to 0.01348, saving model to best_emoji_model.h5\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 28/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0375 - accuracy: 1.0000\n",
      "Epoch 00028: val_loss improved from 0.01348 to 0.01228, saving model to best_emoji_model.h5\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
      "Epoch 29/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0291 - accuracy: 1.0000\n",
      "Epoch 00029: val_loss improved from 0.01228 to 0.01219, saving model to best_emoji_model.h5\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
      "Epoch 30/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 00030: val_loss did not improve from 0.01219\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
      "Epoch 31/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0332 - accuracy: 1.0000\n",
      "Epoch 00031: val_loss did not improve from 0.01219\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0537 - accuracy: 0.9905 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
      "Epoch 32/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0185 - accuracy: 1.0000\n",
      "Epoch 00032: val_loss did not improve from 0.01219\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.0278 - val_accuracy: 1.0000\n",
      "Epoch 33/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0298 - accuracy: 1.0000\n",
      "Epoch 00033: val_loss did not improve from 0.01219\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 1.0000\n",
      "Epoch 34/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0402 - accuracy: 0.9844\n",
      "Epoch 00034: val_loss did not improve from 0.01219\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0350 - accuracy: 0.9905 - val_loss: 0.0359 - val_accuracy: 1.0000\n",
      "Epoch 35/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0207 - accuracy: 1.0000\n",
      "Epoch 00035: val_loss did not improve from 0.01219\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.0305 - val_accuracy: 1.0000\n",
      "Epoch 36/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0219 - accuracy: 1.0000\n",
      "Epoch 00036: val_loss did not improve from 0.01219\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 1.0000\n",
      "Epoch 37/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 00037: val_loss did not improve from 0.01219\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
      "Epoch 38/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0171 - accuracy: 1.0000\n",
      "Epoch 00038: val_loss improved from 0.01219 to 0.01200, saving model to best_emoji_model.h5\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
      "Epoch 39/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0196 - accuracy: 1.0000\n",
      "Epoch 00039: val_loss improved from 0.01200 to 0.00971, saving model to best_emoji_model.h5\n",
      "2/2 [==============================] - 1s 265ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
      "Epoch 40/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0210 - accuracy: 1.0000\n",
      "Epoch 00040: val_loss improved from 0.00971 to 0.00868, saving model to best_emoji_model.h5\n",
      "2/2 [==============================] - 0s 240ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
      "Epoch 41/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0180 - accuracy: 1.0000\n",
      "Epoch 00041: val_loss improved from 0.00868 to 0.00854, saving model to best_emoji_model.h5\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "Epoch 42/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0265 - accuracy: 1.0000\n",
      "Epoch 00042: val_loss did not improve from 0.00854\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 1.0000\n",
      "Epoch 43/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0278 - accuracy: 1.0000\n",
      "Epoch 00043: val_loss did not improve from 0.00854\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
      "Epoch 44/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0115 - accuracy: 1.0000\n",
      "Epoch 00044: val_loss did not improve from 0.00854\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 1.0000\n",
      "Epoch 45/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0255 - accuracy: 1.0000\n",
      "Epoch 00045: val_loss did not improve from 0.00854\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 1.0000\n",
      "Epoch 46/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 00046: val_loss did not improve from 0.00854\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 1.0000\n",
      "Epoch 47/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0222 - accuracy: 1.0000\n",
      "Epoch 00047: val_loss did not improve from 0.00854\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
      "Epoch 48/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0132 - accuracy: 1.0000\n",
      "Epoch 00048: val_loss did not improve from 0.00854\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
      "Epoch 49/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 00049: val_loss did not improve from 0.00854\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
      "Epoch 50/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0199 - accuracy: 1.0000\n",
      "Epoch 00050: val_loss did not improve from 0.00854\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 51/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0120 - accuracy: 1.0000\n",
      "Epoch 00051: val_loss improved from 0.00854 to 0.00810, saving model to best_emoji_model.h5\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
      "Epoch 52/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0233 - accuracy: 1.0000\n",
      "Epoch 00052: val_loss did not improve from 0.00810\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 53/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0139 - accuracy: 1.0000\n",
      "Epoch 00053: val_loss did not improve from 0.00810\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 54/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0133 - accuracy: 1.0000\n",
      "Epoch 00054: val_loss did not improve from 0.00810\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
      "Epoch 55/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0201 - accuracy: 1.0000\n",
      "Epoch 00055: val_loss did not improve from 0.00810\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
      "Epoch 56/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0130 - accuracy: 1.0000\n",
      "Epoch 00056: val_loss did not improve from 0.00810\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
      "Epoch 57/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0171 - accuracy: 1.0000\n",
      "Epoch 00057: val_loss did not improve from 0.00810\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
      "Epoch 58/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0184 - accuracy: 1.0000\n",
      "Epoch 00058: val_loss did not improve from 0.00810\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
      "Epoch 59/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 00059: val_loss did not improve from 0.00810\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
      "Epoch 60/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 00060: val_loss did not improve from 0.00810\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 61/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 00061: val_loss did not improve from 0.00810\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
      "Epoch 62/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 00062: val_loss did not improve from 0.00810\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
      "Epoch 63/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 00063: val_loss did not improve from 0.00810\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
      "Epoch 64/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 00064: val_loss did not improve from 0.00810\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
      "Epoch 65/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 00065: val_loss did not improve from 0.00810\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
      "Epoch 66/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 00066: val_loss did not improve from 0.00810\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
      "Epoch 67/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 00067: val_loss did not improve from 0.00810\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 68/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 00068: val_loss improved from 0.00810 to 0.00788, saving model to best_emoji_model.h5\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
      "Epoch 69/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 00069: val_loss improved from 0.00788 to 0.00776, saving model to best_emoji_model.h5\n",
      "2/2 [==============================] - 0s 194ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 70/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 00070: val_loss improved from 0.00776 to 0.00759, saving model to best_emoji_model.h5\n",
      "2/2 [==============================] - 1s 282ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 71/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 00071: val_loss improved from 0.00759 to 0.00758, saving model to best_emoji_model.h5\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 72/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 00072: val_loss did not improve from 0.00758\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
      "Epoch 73/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 00073: val_loss did not improve from 0.00758\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
      "Epoch 74/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 00074: val_loss did not improve from 0.00758\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
      "Epoch 75/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 00075: val_loss did not improve from 0.00758\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
      "Epoch 76/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 00076: val_loss did not improve from 0.00758\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "Epoch 77/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 00077: val_loss did not improve from 0.00758\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 78/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 00078: val_loss improved from 0.00758 to 0.00735, saving model to best_emoji_model.h5\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 79/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 00079: val_loss did not improve from 0.00735\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 80/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 00080: val_loss did not improve from 0.00735\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
      "Epoch 81/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 00081: val_loss did not improve from 0.00735\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
      "Epoch 82/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0132 - accuracy: 1.0000\n",
      "Epoch 00082: val_loss did not improve from 0.00735\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
      "Epoch 83/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 00083: val_loss did not improve from 0.00735\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 1.0000\n",
      "Epoch 84/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 00084: val_loss did not improve from 0.00735\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0144 - accuracy: 0.9905 - val_loss: 0.0212 - val_accuracy: 1.0000\n",
      "Epoch 85/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 00085: val_loss did not improve from 0.00735\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
      "Epoch 86/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 00086: val_loss did not improve from 0.00735\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0173 - accuracy: 0.9905 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
      "Epoch 87/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 00087: val_loss did not improve from 0.00735\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 88/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 00088: val_loss did not improve from 0.00735\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
      "Epoch 89/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 00089: val_loss did not improve from 0.00735\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0176 - val_accuracy: 1.0000\n",
      "Epoch 90/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0132 - accuracy: 1.0000\n",
      "Epoch 00090: val_loss did not improve from 0.00735\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
      "Epoch 91/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 00091: val_loss did not improve from 0.00735\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
      "Epoch 92/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 00092: val_loss did not improve from 0.00735\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 1.0000\n",
      "Epoch 93/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 00093: val_loss did not improve from 0.00735\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0281 - val_accuracy: 1.0000\n",
      "Epoch 94/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 00094: val_loss did not improve from 0.00735\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 1.0000\n",
      "Epoch 95/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 00095: val_loss did not improve from 0.00735\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0636 - val_accuracy: 0.9630\n",
      "Epoch 96/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0149 - accuracy: 1.0000\n",
      "Epoch 00096: val_loss did not improve from 0.00735\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.0677 - val_accuracy: 0.9630\n",
      "Epoch 97/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0246 - accuracy: 0.9844\n",
      "Epoch 00097: val_loss did not improve from 0.00735\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0174 - accuracy: 0.9905 - val_loss: 0.0232 - val_accuracy: 1.0000\n",
      "Epoch 98/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 00098: val_loss did not improve from 0.00735\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
      "Epoch 99/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 00099: val_loss did not improve from 0.00735\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
      "Epoch 100/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 00100: val_loss did not improve from 0.00735\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
      "Epoch 101/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 00101: val_loss did not improve from 0.00735\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
      "Epoch 102/150\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 00102: val_loss did not improve from 0.00735\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "checkpoint=ModelCheckpoint(\n",
    "    \"best_emoji_model.h5\",\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=True,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    \n",
    ")\n",
    "\n",
    "earlystop=EarlyStopping(monitor='val_accuracy',patience=100)\n",
    "\n",
    "hist=model.fit(embeddings_matrix_train,Y_train,epochs=150,batch_size=64,shuffle=True,validation_split=0.2,callbacks=[checkpoint,earlystop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 1.8366 - accuracy: 0.6071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8365737199783325, 0.6071428656578064]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"best_emoji_model.h5\")\n",
    "model.evaluate(embeddings_matrix_test,Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-33-db8079f3cb55>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict_classes(embeddings_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to eat 🍴 🍴\n",
      "he did not answer 😞 😞\n",
      "he got a raise 😄 😞\n",
      "she got me a present ❤ 😞\n",
      "ha ha ha it was so funny 😄 😄\n",
      "he is a good friend ❤ 😄\n",
      "I am upset ❤ 😞\n",
      "We had such a lovely dinner tonight ❤ 😄\n",
      "where is the food 🍴 🍴\n",
      "Stop making this joke ha ha ha 😄 😄\n",
      "where is the ball ⚾ ⚾\n",
      "work is hard 😞 😞\n",
      "This girl is messing with me 😞 😞\n",
      "are you serious ha ha 😄 😞\n",
      "Let us go play baseball ⚾ ⚾\n",
      "This stupid grader is not working 😞 😞\n",
      "work is horrible 😞 😞\n",
      "Congratulation for having a baby 😄 😄\n",
      "stop messing around 😞 😞\n",
      "any suggestions for dinner 🍴 😄\n",
      "I love taking breaks ❤ ❤\n",
      "you brighten my day 😄 ❤\n",
      "I boiled rice 🍴 🍴\n",
      "she is a bully 😞 ❤\n",
      "Why are you feeling bad 😞 😞\n",
      "I am upset 😞 😞\n",
      "I worked during my birthday 😞 😄\n",
      "My grandmother is the love of my life ❤ ❤\n",
      "enjoy your break 😄 ⚾\n",
      "valentine day is near ❤ 😄\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    print(' '.join(X_test[i]),end=\" \")\n",
    "    print(emoji.emojize( emoji_dict[np.argmax(Y_test[i])], use_aliases=True),end=\" \" )\n",
    "    print(emoji.emojize(emoji_dict[pred[i]], use_aliases=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting for our random sentence\n",
    "x1 = ['I', 'love', 'dogs']\n",
    "#x = \"I love dogs\"\n",
    "\n",
    "x1_ = np.zeros((1,10,50))\n",
    "\n",
    "for ix in range(len(x)):\n",
    "    x1_[0][ix] = embeddings_index[x1[ix].lower()]\n",
    "\n",
    "x2 = ['I', 'do','not','like' ,'cats']\n",
    "\n",
    "x2_ = np.zeros((1,10,50))\n",
    "\n",
    "for ix in range(len(x)):\n",
    "    x2_[0][ix] = embeddings_index[x2[ix].lower()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love dogs ❤\n",
      "I do not like cats 😞\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict_classes(x1_)\n",
    "print(' '.join(x1),end=\" \")\n",
    "print(emoji.emojize(emoji_dict[pred[0]], use_aliases=True),end=\"\\n\")\n",
    "pred=model.predict_classes(x2_)\n",
    "print(' '.join(x2),end=\" \")\n",
    "print(emoji.emojize(emoji_dict[pred[0]], use_aliases=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model\n",
    "## Using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 10, 128)           91648     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 223,877\n",
      "Trainable params: 223,877\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(10,50), return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.5805 - accuracy: 0.2197\n",
      "Epoch 2/150\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.5097 - accuracy: 0.3712\n",
      "Epoch 3/150\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.4564 - accuracy: 0.3939\n",
      "Epoch 4/150\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.3784 - accuracy: 0.4621\n",
      "Epoch 5/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.3026 - accuracy: 0.4848\n",
      "Epoch 6/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.1580 - accuracy: 0.5606\n",
      "Epoch 7/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.0981 - accuracy: 0.5909\n",
      "Epoch 8/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.9692 - accuracy: 0.6591\n",
      "Epoch 9/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.8618 - accuracy: 0.6970\n",
      "Epoch 10/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.8000 - accuracy: 0.7121\n",
      "Epoch 11/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.7685 - accuracy: 0.6894\n",
      "Epoch 12/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.6726 - accuracy: 0.7424\n",
      "Epoch 13/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.5631 - accuracy: 0.8106\n",
      "Epoch 14/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.4764 - accuracy: 0.8485\n",
      "Epoch 15/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.4188 - accuracy: 0.8712\n",
      "Epoch 16/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.4059 - accuracy: 0.8712\n",
      "Epoch 17/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.4000 - accuracy: 0.8636\n",
      "Epoch 18/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.4584 - accuracy: 0.8561\n",
      "Epoch 19/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2920 - accuracy: 0.8712\n",
      "Epoch 20/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.3364 - accuracy: 0.8485\n",
      "Epoch 21/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2412 - accuracy: 0.9242\n",
      "Epoch 22/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.3680 - accuracy: 0.8636\n",
      "Epoch 23/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.3322 - accuracy: 0.8864\n",
      "Epoch 24/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2512 - accuracy: 0.9091\n",
      "Epoch 25/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1690 - accuracy: 0.9545\n",
      "Epoch 26/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1502 - accuracy: 0.9470\n",
      "Epoch 27/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1311 - accuracy: 0.9621\n",
      "Epoch 28/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1831 - accuracy: 0.9394\n",
      "Epoch 29/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1806 - accuracy: 0.9318\n",
      "Epoch 30/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1333 - accuracy: 0.9470\n",
      "Epoch 31/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1365 - accuracy: 0.9621\n",
      "Epoch 32/150\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0944 - accuracy: 0.9773\n",
      "Epoch 33/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0934 - accuracy: 0.9697\n",
      "Epoch 34/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0644 - accuracy: 0.9924\n",
      "Epoch 35/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0649 - accuracy: 0.9773\n",
      "Epoch 36/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.4430 - accuracy: 0.8788\n",
      "Epoch 37/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.4865 - accuracy: 0.8485\n",
      "Epoch 38/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2008 - accuracy: 0.9394\n",
      "Epoch 39/150\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.3193 - accuracy: 0.8788\n",
      "Epoch 40/150\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1243 - accuracy: 0.9621\n",
      "Epoch 41/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1388 - accuracy: 0.9621\n",
      "Epoch 42/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0900 - accuracy: 0.9848\n",
      "Epoch 43/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0752 - accuracy: 0.9924\n",
      "Epoch 44/150\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0605 - accuracy: 0.9848\n",
      "Epoch 45/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0464 - accuracy: 0.9924\n",
      "Epoch 46/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0409 - accuracy: 1.0000\n",
      "Epoch 47/150\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0317 - accuracy: 0.9924\n",
      "Epoch 48/150\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0258 - accuracy: 1.0000\n",
      "Epoch 49/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0218 - accuracy: 1.0000\n",
      "Epoch 50/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 51/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 52/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 53/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 54/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 55/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 56/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 57/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 58/150\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 59/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 60/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 61/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 62/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 63/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 64/150\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 65/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 66/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 67/150\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 68/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 69/150\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 70/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0032 - accuracy: 1.0000 0s - loss: 0.0028 - accuracy: 1.00\n",
      "Epoch 71/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 72/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 73/150\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 74/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 75/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 76/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 77/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0095 - accuracy: 0.9924\n",
      "Epoch 78/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0276 - accuracy: 0.9924\n",
      "Epoch 79/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0960 - accuracy: 0.9773\n",
      "Epoch 80/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0897 - accuracy: 0.9773\n",
      "Epoch 81/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0149 - accuracy: 1.0000\n",
      "Epoch 82/150\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1464 - accuracy: 0.9545\n",
      "Epoch 83/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0615 - accuracy: 0.9621\n",
      "Epoch 84/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0384 - accuracy: 0.9924\n",
      "Epoch 85/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0636 - accuracy: 0.9773\n",
      "Epoch 86/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0235 - accuracy: 1.0000\n",
      "Epoch 87/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 88/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 89/150\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 90/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 91/150\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 92/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 93/150\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 94/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 95/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 96/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 97/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 98/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 99/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 100/150\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 101/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 102/150\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 103/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 104/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 105/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 106/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 107/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 108/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 109/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 110/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.2677e-04 - accuracy: 1.0000\n",
      "Epoch 111/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 112/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 113/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 114/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.2499e-04 - accuracy: 1.0000\n",
      "Epoch 116/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 117/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 118/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.7036e-04 - accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 120/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.9051e-04 - accuracy: 1.0000\n",
      "Epoch 121/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.2781e-04 - accuracy: 1.0000\n",
      "Epoch 122/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.3403e-04 - accuracy: 1.0000\n",
      "Epoch 123/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 124/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.3545e-04 - accuracy: 1.0000\n",
      "Epoch 125/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.3605e-04 - accuracy: 1.0000\n",
      "Epoch 127/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.6968e-04 - accuracy: 1.0000\n",
      "Epoch 128/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.9837e-04 - accuracy: 1.0000\n",
      "Epoch 129/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.5585e-04 - accuracy: 1.0000\n",
      "Epoch 132/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.7093e-04 - accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.8052e-04 - accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 135/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.9240e-04 - accuracy: 1.0000\n",
      "Epoch 136/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.9049e-04 - accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.3280e-04 - accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.1621e-04 - accuracy: 1.0000\n",
      "Epoch 139/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.7476e-04 - accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.5558e-04 - accuracy: 1.0000\n",
      "Epoch 141/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.5631e-04 - accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.0099e-04 - accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 6.6516e-04 - accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.4068e-04 - accuracy: 1.0000\n",
      "Epoch 145/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.1617e-04 - accuracy: 1.0000\n",
      "Epoch 146/150\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 6.0198e-04 - accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.6451e-04 - accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.9586e-04 - accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.2948e-04 - accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.8493e-04 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(embeddings_matrix_train,Y_train,epochs=150,batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 2.2851 - accuracy: 0.6250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.2850537300109863, 0.625]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(embeddings_matrix_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_classes(embeddings_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to eat 🍴 🍴\n",
      "he did not answer 😞 😞\n",
      "he got a raise 😄 😞\n",
      "she got me a present ❤ ❤\n",
      "ha ha ha it was so funny 😄 😄\n",
      "he is a good friend ❤ 😄\n",
      "I am upset ❤ 😞\n",
      "We had such a lovely dinner tonight ❤ 😄\n",
      "where is the food 🍴 🍴\n",
      "Stop making this joke ha ha ha 😄 😄\n",
      "where is the ball ⚾ ⚾\n",
      "work is hard 😞 😄\n",
      "This girl is messing with me 😞 ❤\n",
      "are you serious ha ha 😄 😞\n",
      "Let us go play baseball ⚾ ⚾\n",
      "This stupid grader is not working 😞 😞\n",
      "work is horrible 😞 😄\n",
      "Congratulation for having a baby 😄 😄\n",
      "stop messing around 😞 😞\n",
      "any suggestions for dinner 🍴 😄\n",
      "I love taking breaks ❤ ❤\n",
      "you brighten my day 😄 ❤\n",
      "I boiled rice 🍴 🍴\n",
      "she is a bully 😞 ❤\n",
      "Why are you feeling bad 😞 😞\n",
      "I am upset 😞 😞\n",
      "I worked during my birthday 😞 😄\n",
      "My grandmother is the love of my life ❤ ❤\n",
      "enjoy your break 😄 ⚾\n",
      "valentine day is near ❤ 😄\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    print(' '.join(X_test[i]),end=\" \")\n",
    "    print(emoji.emojize( emoji_dict[np.argmax(Y_test[i])], use_aliases=True),end=\" \" )\n",
    "    print(emoji.emojize(emoji_dict[pred[i]], use_aliases=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
